# Issue Guide: Structured Logging and Observability Upgrade – ARK Resolver Migration

## Overview and General Instructions

This guide outlines a sequence of incremental development tasks
("issues") for a junior developer contributing to the ARK Resolver
migration and observability upgrade. **These issues are to be worked on
one at a time.**

- **Before starting any issue,** read the description and checklist
  carefully.

- **Do not move to the next issue until your work has been reviewed and
  approved** (by the assigned team lead or reviewer).

- Feedback and discussion are expected after each step. This ensures
  clarity, avoids wasted effort, and keeps the project focused.

- If you have any doubts or run into blockers, ask your lead for
  guidance immediately before attempting workarounds.

------------------------------------------------------------------------

## Issue 1 – Design Structured Error Log Format

**Purpose:**  
Define the schema and documentation for error logs generated by ARK
Resolver.

**Task Details:**

- Design a JSON structure that will be used to log details of failed or
  discrepant ARK requests.

- Specify the exact fields required:

  - timestamp: When the request was processed (ISO 8601 or comparable
    format)

  - ark: The ARK string that was requested

  - project: Project identifier (from ARK path segment, if available)

  - error_type: Category of error (e.g., invalid_input, not_found,
    backend_failure, discrepancy)

  - python_result: Output or error from the Python implementation

  - rust_result: Output or error from the Rust implementation

  - discrepancy: Boolean flag: true if Python and Rust results don’t
    match

  - user_hash: Hashed user identifier, generated from the request’s
    source IP (never store or log raw IP addresses; use a salted,
    one-way hash)

- **Create a concise markdown file (**docs/log-schema.md**)
  documenting:**

  - The JSON structure describing fields and their types (do not create
    an actual JSON schema file; documentation only).

  - How and why the IP address is hashed (summarize privacy rationale)

  - Example log entry

**Important:**

- **Do not write or change any application code yet.**

- **Do not create a formal JSON schema file.**

- **Do not implement the schema as a model in Python or any code.**

- Focus solely on schema design and documentation in markdown.

- **WARNING:** If you are unsure whether an action counts as code or
  implementation, stop and ask your team lead before proceeding.

**Acceptance Checklist:**

- A markdown file with the schema and documentation exists in the
  codebase.

- All required fields (see above) are clearly explained.

- Example for at least one error case (as a JSON snippet).

- Privacy handling for user/IP is described and justified.

- Team lead has reviewed and approved the schema before any
  implementation work.

------------------------------------------------------------------------

## Issue 2 – Implement Logging for Failed or Discrepant Requests

**Purpose:**  
Update the Python ARK Resolver to emit structured logs only for failed
or discrepant requests.

**Task Details:**

- Update the application code (Python) so that:

  - Whenever a request fails (invalid ARK, resource not found, backend
    failure) OR

  - There is a discrepancy in results between Python and Rust
    implementations,  
    a structured log entry (following the schema from Issue 1) is
    produced and sent to the logging backend (OpenTelemetry to Grafana
    Loki).

- **Do not log successful and matching requests.**

- Do not add extra logging for debugging unrelated to errors or
  discrepancies.

**Checklist:**

- Logging code only triggers on error or discrepancy (not on every
  request).

- Log entries match the agreed format/schema.

- No logs appear for successful, matching requests.

- Relevant unit and/or integration tests show log creation for each type
  of failure/discrepancy.

- Team lead verifies the logs before moving on.

------------------------------------------------------------------------

## Issue 3 – Add Discrepancy Detection Between Python and Rust

**Purpose:**  
Detect and log whenever the Python and Rust ARK Resolver implementations
return different results.

**Task Details:**

- Every request should be processed through both the existing Python
  handler and the new Rust handler.

- Compare outputs and categorize as:

  - Matching result: no action needed.

  - Mismatched result: set discrepancy flag to true and record both
    python_result and rust_result in the log entry.

- Only the Python result should be returned to the user (no change to
  visible user experience or external API).

**Checklist:**

- Every request is processed by both implementations.

- Discrepancies are detected, flagged, and logged as structured error
  entries.

- No changes to current user-visible behavior (Python is always the
  source of truth).

- Tests exist for standard, failure, and discrepancy cases.

- Review completed before proceeding.

------------------------------------------------------------------------

## Issue 4 – Emit Observability Metrics via OpenTelemetry

**Purpose:**  
Track key service events without logging every request.

**Task Details:**

- Add metrics emission to the ARK Resolver using OpenTelemetry:

  - Total number of requests

  - Number of successful requests

  - Number of failed requests (by error type)

  - Number of discrepancies (Python vs. Rust)

- Metrics should be sent to Grafana Cloud and usable for dashboards and
  alerting.

- **Do not create logs for successful requests.**

**Checklist:**

- Metrics (counters) are emitted for all key categories.

- Metrics are visible and updating in Grafana Cloud.

- Metrics are broken down by project where possible.

- No full log entries are created for successes.

- Team lead reviews metrics output and confirms no excess logging.

------------------------------------------------------------------------

## Issue 5 – Build Grafana Dashboards

**Purpose:**  
Create actionable, insightful dashboards showing the health and usage of
ARK Resolver.

**Task Details:**

- Use available metrics and error logs to build dashboards with the
  following panels:

  - Request volume (by hour/day/week)

  - Failure % and count (overall and by error type)

  - Discrepancy % and count

  - Top N failing ARKs (from log data)

  - Breakdown by project (if possible)

- Only build visuals for data you know exists (do not create panels
  relying on unavailable events).

**Checklist:**

- Grafana dashboards include all required panels above, clearly labeled.

- Top errors/failures table is pulling directly from log data.

- Dashboard URLs/locations are documented in project README or wiki.

- Review and approval from team lead before sharing more widely.

------------------------------------------------------------------------

## Issue 6 – Set Up Log Retention and Data Privacy Controls

**Purpose:**  
Enforce compliance and good practices for data privacy and retention.

**Task Details:**

- Ensure code **never** stores, logs, or transmits raw IP addresses.  
  Only a salted, one-way hashed user identifier may appear in logs.

- Confirm that log retention in Grafana Cloud matches organizational
  policy (typically, the default is sufficient unless directed
  otherwise).

- Document log handling and privacy rationale in project README or
  internal wiki.

**Checklist:**

- Raw IP addresses are never used in logs.

- Hashing approach is consistent and clearly implemented.

- Confirmed with test logs and log search (no IPs present).

- Log retention policies are known and documented.

- Documentation updated and reviewed for compliance.

------------------------------------------------------------------------

## Issue 7 – Document the Migration and New Observability Approach

**Purpose:**  
Quickly orient other team members or future contributors on how and why
the new observability and logging model works.

**Task Details:**

- Write a concise markdown or wiki page that covers:

  - The central motivation: moving from Sentry to Grafana for
    centralization and operational control.

  - How errors, discrepancies, and metrics are now handled (logs for
    failures/discrepancies only; metrics for volume, accuracy, and
    visibility).

  - Where to find logs, dashboards, and metrics.

  - Privacy practices, especially IP hashing.

- Focus on brevity, clarity, and practical info—avoid unnecessary
  detail.

**Checklist:**

- A brief document/wiki entry exists covering all points above.

- Link is placed in main project README for discoverability.

- Language is clear and accessible for junior/new team members.

- Reviewed before marking as done.

------------------------------------------------------------------------

## Issue 8 – Sunset Sentry Spans for ARK Resolver

**Purpose:**  
Remove legacy, now-redundant monitoring code.

**Task Details:**

- Only after approval from tech or product lead (when all logs,
  dashboards, and metrics are verified and live in Grafana), remove
  Sentry integration and any related documentation.

**Important:**

- **Do not begin until explicitly instructed by your team lead.**

**Checklist:**

- All Sentry code and config for ARK Resolver is removed.

- Documentation and deployment scripts are updated.

- Team is notified of completed Sentry removal.

------------------------------------------------------------------------
